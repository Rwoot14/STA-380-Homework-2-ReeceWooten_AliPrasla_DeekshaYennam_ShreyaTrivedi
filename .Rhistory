}
trainingCorpus = Corpus(VectorSource(l))
trainingCorpus = tm_map(trainingCorpus, content_transformer(tolower)) # make everything lowercase
trainingCorpus = tm_map(trainingCorpus, content_transformer(removeNumbers)) # remove numbers
trainingCorpus = tm_map(trainingCorpus, content_transformer(removePunctuation)) # remove punctuation
trainingCorpus = tm_map(trainingCorpus, content_transformer(stripWhitespace))
trainingCorpus = tm_map(trainingCorpus,content_transformer(removeWords),stopwords("en"))
allAuthorsInTestSet = list.files("ReutersC50/c50test")
l = foreach( i = 1:length(allAuthorsInTrainingSet),.combine = 'c') %do% {
author = allAuthorsInTestSet[i]
fpath = paste("ReutersC50/c50test/",author,"/*.txt",sep = "")
file_list = Sys.glob(fpath)
current = lapply(file_list,readerPlain)
mynames = file_list %>%
{ strsplit(., '/', fixed=TRUE) } %>%
{ lapply(., tail, n=2) } %>%
{ lapply(., paste0, collapse = '') } %>%
unlist
current
}
testCorpus = Corpus(VectorSource(l))
testCorpus = tm_map(testCorpus,content_transformer(removeWords),stopwords("en"))
#testWithoutEN = tm_map(testCorpus,content_transformer(removeWords),stopwords("en"))
#construct Document Term Matrix and convert to TF-IDF
DTMTrainSimple = DocumentTermMatrix(trainingCorpus,control = list(weighting = function(x) weightTfIdf(x)))
dropTermPercent = .95
DTMTrainSimple =removeSparseTerms(DTMTrainSimple,dropTermPercent)
pcaTrainSimple = prcomp(DTMTrainSimple,scale = TRUE)
par(bg = "gray")
plot(pcaTrainSimple$sdev^2,type = "l",main = "Projection Error for number of Principle Components",col = "blue",xlab = "Number of Principal Components",ylab = "Projection Error (Variance)")
bestComponents = 150
abline(v = bestComponents ,lw = 2,col = "red")
x = as.matrix(DTMTrainSimple)
V = t(t(pcaTrainSimple$rotation)[1:bestComponents,])
x = x %*% V
response = sort(rep(allAuthorsInTrainingSet,50))
testCorpus = tm_map(testCorpus, content_transformer(tolower)) # make everything lowercase
testCorpus = tm_map(testCorpus, content_transformer(removeNumbers)) # remove numbers
testCorpus = tm_map(testCorpus, content_transformer(removePunctuation)) # remove punctuation
testCorpus = tm_map(testCorpus, content_transformer(stripWhitespace))
DTMTestSet = DocumentTermMatrix(testCorpus,control = list(weighting = function(x) weightTfIdf(x)))
pcaTest = predict(pcaTrainSimple,newdata = DTMTestSet)
testX = pcaTest[,1:bestComponents]
testResponse = response
library(naivebayes)
tr = naive_bayes(x = x, y= as.factor(response))
pred = predict(tr,data.frame(testX))
classificationRate = length(which(pred == testResponse))/length(testResponse)
classificationRate
library(randomForest)
bag = randomForest(as.factor(response) ~.,data = data.frame(x),mtry =bestComponents,ntree = 1000)
library(randomForest)
bag = randomForest(as.factor(response) ~.,data = data.frame(x),mtry =bestComponents,ntree = 100)
pred = predict(bag,data.frame(testX))
classificationRate = length(which(pred == testResponse))/length(testResponse)
classificationRate
pred
View(c(pred,testResponse))
c(pred,testResponse)
pred == testResponse
sum(pred == testResponse)
testResponse = response
getClassificationRate = function(model,testX,testY){
pred = predict(model,data.frame(testX))
sum(pred == testY)/length(pred)
}
library(naivebayes)
nb = naive_bayes(x = x, y= as.factor(response))
getClassificationRate(nb,testX,testResponse)
library(randomForest)
testTrees = c(1,2,5,10,20,40,60,100,120,180,200)
bag = randomForest(as.factor(response) ~.,data = data.frame(x),mtry =bestComponents,ntree = 100)
getClassificationRate(nb,testX,testResponse)
library(randomForest)
testTrees = c(1,2,5,10,20,40,60,100,120,180,200)
bag = randomForest(as.factor(response) ~.,data = data.frame(x),mtry =bestComponents,ntree = 100)
getClassificationRate(bag,testX,testResponse)
library(randomForest)
testTrees = c(1,2,5,10,20,40,60,100,120,180,200)
randomForestClass = foreach( i = 1:length(testTrees),.combine = 'c') %do%
{
bag = randomForest(as.factor(response) ~.,data = data.frame(x),mtry =bestComponents,ntree = testTrees[i])
getClassificationRate(bag,testX,testResponse)
}
?dopar
??dopar
library(doParallel)
registerDoParallel(cluster(4))
registerDoParallel(makeCluster(4))
library(randomForest)
library(doParallel)
registerDoParallel(makeCluster(4))
testTrees = c(1,2,5,10,20,40,60,100,120,180,200)
randomForestClass = foreach( i = 1:length(testTrees),.combine = 'c') %dopar%
{
bag = randomForest(as.factor(response) ~.,data = data.frame(x),mtry =bestComponents,ntree = testTrees[i])
getClassificationRate(bag,testX,testResponse)
}
library(randomForest)
library(doParallel)
registerDoParallel(makeCluster(4))
testTrees = c(1,2,5,10,20,40,60,100,120,180,200)
randomForestClass = foreach( i = 1:length(testTrees),.combine = 'c') %dopar%
{
bag = randomForest::randomForest(as.factor(response) ~.,data = data.frame(x),mtry =bestComponents,ntree = testTrees[i])
getClassificationRate(bag,testX,testResponse)
}
library(randomForest)
library(doParallel)
registerDoParallel(cores = 3)
testTrees = c(1,2,5,10,20,40,60,100,120,180,200)
randomForestClass = foreach( i = 1:length(testTrees),.combine = 'c') %dopar%
{
bag = randomForest::randomForest(as.factor(response) ~.,data = data.frame(x),mtry =bestComponents,ntree = testTrees[i])
getClassificationRate(bag,testX,testResponse)
}
randomForestClass
plot(randomForestClass)
plot(randomForestClass,type = "l")
plot(testTrees,randomForestClass,type = "l")
library(randomForest)
library(doParallel)
registerDoParallel(cores = 3)
testTrees = c(1,2,5,10,20,40,60,100,120,180,200)
randomForestClass = foreach( i = 1:length(testTrees),.combine = 'c') %dopar%
{
bag = randomForest::randomForest(as.factor(response) ~.,data = data.frame(x),mtry =bestComponents/2,ntree = testTrees[i])
getClassificationRate(bag,testX,testResponse)
}
getClassificationRate(bag,testX,testResponse)
plot(testTrees,randomForestClass,type = "l")
randomForestClass
library(randomForest)
library(doParallel)
registerDoParallel(cores = 3)
testTrees = c(1,2,5,10,20,40,60,100,120,180,200)
bagClass = foreach( i = 1:length(testTrees),.combine = 'c') %dopar%
{
bag = randomForest::randomForest(as.factor(response) ~.,data = data.frame(x),mtry =bestComponents,ntree = testTrees[i])
getClassificationRate(bag,testX,testResponse)
}
par(bg = "gray")
plot(testTrees,randomForestClass,type = "l", col = "red")
print(paste("Best Out-of-Sample Classification Rate: ", bagClass.max()))
par(bg = "gray")
plot(testTrees,randomForestClass,type = "l", col = "red")
print(paste("Best Out-of-Sample Classification Rate: ", max(bagClass),lw = 2,main = "Bagging in Decision Trees: Classification Rate vs Number of Trees",xlab = "Number of Trees",ylab = "Classification Rate")
par(bg = "gray")
plot(testTrees,randomForestClass,type = "l", col = "red",lw = 2,main = "Bagging in Decision Trees: Classification Rate vs Number of Trees",xlab = "Number of Trees",ylab = "Classification Rate")
plot(testTrees,randomForestClass,type = "l", col = "red",main = "Bagging in Decision Trees: Classification Rate vs Number of Trees",xlab = "Number of Trees",ylab = "Classification Rate")
print(paste("Best Out-of-Sample Classification Rate: ", max(bagClass)))
par(bg = "gray")
plot(testTrees,randomForestClass,type = "l", col = "red",main = "Bagging in Decision Trees: Classification Rate vs Number of Trees",xlab = "Number of Trees",ylab = "Classification Rate")
print(paste("Best Out-of-Sample Classification Rate: ", max(bagClass)))
library(glmnet)
logistic = glm(as.factor(response) ~.,data = data.frame(x))
logistic = glm(as.factor(response) ~.,data = data.frame(x),family = 'multinomial')
logistic = glmnet(as.factor(response) ~.,data = data.frame(x),family = 'multinomial')
logistic = glmnet(x = x,as.factor(response),family = 'multinomial')
library(glmnet)
logistic = glmnet(x = x,as.factor(response),family = 'multinomial',lambda = .3)
getClassificationRate(logistic,testX,testResponse)
getClassificationRate(logistic,as.matrix(testX),as.matrix(testResponse))
pred = predict(logistic,testX)
sum(pred == testResponse)/length(pred)
pred
dim(pred)
pred[1,,]
which.max(pred[1,,])
names(which.max(pred[1,,]))
names(which.max(pred[1:nrow(pred),,]))
which.max(pred[1:nrow(pred),,])
pred[1:nrow(pred),,]
dim(pred[1:nrow(pred),,])
names(which.max(pred[1:nrow(pred),,]))
names(which.max(pred[1,,]))
getBestChoice = function(x){
names(which.max(x))
}
pred.apply(getBestChoice)
data.frame(pred).apply(getBestChoice)
getBestChoice()
getBestChoice
data.frame(pred).apply(function(x) names(which.max(x)))
pred.apply(function(x) names(which.max(x)))
apply(pred,function(x) names(which.max(x)))
apply(pred,1,function(x) names(which.max(x)))
colMax
apply(pred,2,function(x) max(x))
names(apply(pred,2,function(x) max(x)))
length(names(apply(pred,2,function(x) max(x))))
length(names(apply(pred,1,function(x) max(x))))
library(glmnet)
logistic = glmnet(x = x,as.factor(response),family = 'multinomial',lambda = .3)
pred = predict(logistic,testX)
predNames = names(apply(pred,1,function(x) max(x)))
sum(predNames == testResponse)/length(predNames)
predNames
predNames = apply(pred,1,function(x) max(x))
predNames
apply(pred,1,function(x) max(x))
max(apply(pred,1,function(x) max(x)))
names(apply(pred,1,function(x) max(x)))
predNames = apply(pred,2,function(x) max(x))
predNames
dim(predNames)
length(predNames)
pred
dim(pred)
pred = pred[,,1]
dim(pred)
library(glmnet)
logistic = glmnet(x = x,as.factor(response),family = 'multinomial',lambda = .3)
pred = predict(logistic,testX)
pred = pred[,,1]
predNames = apply(pred,2,function(x) max(x))
sum(predNames == testResponse)/length(predNames)
pred
dim(pred)
names(pred)
colnames(pred)
apply(pred,2,function(x) max(x,na.rm = TRUE))
apply(pred,!,function(x) max(x,na.rm = TRUE))
apply(pred,1,function(x) max(x,na.rm = TRUE))
apply(pred,1,max)
apply(pred,1,which.max)
50/2500
library(glmnet)
logistic = glmnet(x = x,as.factor(response),family = 'multinomial',lambda = .13)
pred = predict(logistic,testX)
pred = pred[,,1]
apply(pred,1,which.max)
library(glmnet)
logistic = glmnet(x = x,as.factor(response),family = 'multinomial',lambda = .13)
pred = predict(logistic,testX)
apply(pred,1,which.max)
library(glmnet)
logistic = glm(as.factor(response) ~.,family = 'multinomial',data = data.frame(x),lambda = .13)
logistic = glm(as.factor(response) ~.,data = data.frame(x),family = 'multinomial',lambda = .13)
logistic = glm(as.factor(response) ~.,data = data.frame(x),family = multinomial,lambda = .13)
logistic = multinom(as.factor(response) ~.,data = data.frame(x))
??multinom
library(gbm)
logistic = multinom(as.factor(response) ~.,data = data.frame(x))
install.packages("nnet")
library(nnet)
logistic = multinom(as.factor(response) ~.,data = data.frame(x))
model = knn(x,response,k = 20)
library(kknn)
model = knn(x,response,k = 20)
??knn
library(caret)
library(caret)
model = knn(x,response,k = 20)
model = knn3(x,response,k = 20)
model = knn3(x,as.factor(response),k = 20)
model
getClassificationRate(model,testX,testResponse)
model
predict(model,testResponse)
predict(testResponse,model)
model = knn3(x= x,y =as.factor(response),k = 20)
predict(model.newdata = testResponse)
predict(model.newdata = as.factor(testResponse))
model
predict(model,testResponse)
predict(model,testX)
length(predict(model,testX))
dim(predict(model,testX))
getClassificationRate(model,testX,testResponse)
predict(model,testX)
pred = predict(model,testX)
dim(pred)
pred[1,]
which.max(pred[1,])
pred = predict(model,testX)
pred
dim(pred)
pred
pred[1,]
which.max(pred[1,])
df = pred
colnames(df)[apply(df,1,which.max)]
length(colnames(df)[apply(df,1,which.max)])
pred = colnames(data.frame(pred)[apply(data.frame(pred),1,which.max)])
pred
length(pred)
library(caret)
model = knn3(x= x,y =as.factor(response),k = 20)
pred = predict(model,testX)
pred = colnames(data.frame(pred)[apply(data.frame(pred),1,which.max)])
sum(pred == testResponse)/length(testResponse)
?knn3
model = caret::knn3(x= x,y =as.factor(response),k = testK[i],method = 'manhattan')
testK = c(1,5,10,20,40,80,160,320,640)
model = caret::knn3(x= x,y =as.factor(response),k = testK[i],method = 'manhattan')
library(caret)
testK = c(1,5,10,20,40,80,160,320,640)
knnClassificationRates = foreach(i = 1:length(testK),.combine ='c') %dopar%{
model = caret::knn3(x= x,y =as.factor(response),k = testK[i],method = 'manhattan')
pred = predict(model,testX)
pred = colnames(data.frame(pred)[apply(data.frame(pred),1,which.max)])
sum(pred == testResponse)/length(testResponse)
}
install.packages("knnGarden")
library(knnGarden)
model = knnGarden::knnVCN(x,as.factor(response),k = testK[i],method = 'manhattan')
model = knnGarden::knnVCN(x,as.factor(response),K = testK[i],method = 'manhattan')
model = knnGarden::knnVCN(x,as.factor(response),K = testK[i],method = 'manhattan')
i
testK = c(1,5,10,20,40,80,160)
model = knnGarden::knnVCN(x,as.factor(response),K = 5,method = 'manhattan')
library(knnGarden)
testK = c(1,5,10,20,40,80,160)
knnClassificationRates = foreach(i = 1:length(testK),.combine ='c') %dopar%{
model = knnGarden::knnVCN(x,as.factor(response),K = testK[i],method = 'manhattan')
pred = predict(model,testX)
pred = colnames(data.frame(pred)[apply(data.frame(pred),1,which.max)])
sum(pred == testResponse)/length(testResponse)
}
library(knnGarden)
testK = c(80,160)
knnClassificationRates = foreach(i = 1:length(testK),.combine ='c') %dopar%{
model = knnGarden::knnVCN(x,as.factor(response),K = testK[i],method = 'manhattan')
pred = predict(model,testX)
pred = colnames(data.frame(pred)[apply(data.frame(pred),1,which.max)])
sum(pred == testResponse)/length(testResponse)
}
model = knnGarden::knnVCN(x,as.factor(response),K = 1,method = 'manhattan')
boost = gbm(as.factor(response)~.,n.trees = 10)
boost = gbm(as.factor(response)~.,data = x,n.trees = 10)
boost = gbm(as.factor(response)~.,data = data.frame(x),n.trees = 10)
getClassificationRate(boost,testX,testResponse)
boost = gbm(as.factor(response)~.,data = data.frame(x),n.trees = 10)
getClassificationRate(boost,testX,testResponse)
pred = predict(boost,testX)
pred = predict(boost,testX,n.trees = 10)
pred = predict(boost,data.frame(testX),n.trees = 10)
pred
library(gbm)
boost = gbm(as.factor(response)~.,data = x,n.trees = 10)
library(gbm)
boost = gbm(as.factor(response)~.,data = data.frame(x),n.trees = 10)
pred = predict(boost,data.frame(testX),n.trees = 10)
pred = colnames(data.frame(pred)[apply(data.frame(pred),1,which.max)])
sum(pred == testResponse)/length(testResponse)
pred
V
rownames(V)
pre
pred
pred = predict(boost,data.frame(testX),n.trees = 10)
pred = colnames(data.frame(pred)[apply(data.frame(pred),2,which.max)])
pred = colnames(data.frame(pred)[apply(data.frame(pred),1,which.max)])
pred
nb
predict(nb,testX)
pred =predict(nb,testX)
sum(pred == testResponse)
pred = predict(boost,data.frame(testX),n.trees = 10)
pred
pred = colnames(data.frame(pred)[apply(data.frame(pred),2,which.max)])
pred
pred = colnames(data.frame(pred)[apply(data.frame(pred),2,which.max)])
apply(data.frame(pred),2,which.max)
colnames(pred)
apply(data.frame(pred),1,which.max)
colnames(pred)
pred = colnames(data.frame(pred))[apply(data.frame(pred),2,which.max)]
pred
pred = colnames(data.frame(pred))[apply(data.frame(pred),1,which.max)]
pred
apply(data.frame(pred),1,which.max)
apply(data.frame(pred),2,which.max)
pred = predict(boost,data.frame(testX),n.trees = 10)
apply(data.frame(pred),2,which.max)
apply(data.frame(pred),1,which.max)
idxList = apply(data.frame(pred),1,which.max)
colnames(pred)
colnames(pred)[idxList]
pred = colnames(pred)[apply(data.frame(pred),1,which.max)]
pred
length(pred)
sum(pred == testResponse)/length(testResponse)
?gbm
library(gbm)
boost = gbm(as.factor(response)~.,data = data.frame(x),n.trees = 10,shrinkage = .02,interaction.depth = 4)
pred = predict(boost,data.frame(testX),n.trees = 10)
pred = colnames(pred)[apply(data.frame(pred),1,which.max)]
sum(pred == testResponse)/length(testResponse)
library(gbm)
boost = gbm(as.factor(response)~.,data = data.frame(x),n.trees = 100,shrinkage = .002,interaction.depth = 4)
pred = predict(boost,data.frame(testX),n.trees = 10)
pred = colnames(pred)[apply(data.frame(pred),1,which.max)]
sum(pred == testResponse)/length(testResponse)
library(gbm)
boost = gbm(as.factor(response)~.,data = data.frame(x),n.trees = 50,shrinkage = .02,interaction.depth = 4)
testTrees = testTrees/2
testTrees
testTrees[:1]
testTrees[2:length(testTrees)]
library(gbm)
testTrees = testTrees/2
testTrees = testTrees[2:length(testTrees)]
boostClass = foreach(i = 1:length(testTrees),.combine = 'c') %dopar%{
boost = gbm(as.factor(response)~.,data = data.frame(x),n.trees = testTrees[i],shrinkage = .02,interaction.depth = 4)
pred = predict(boost,data.frame(testX),n.trees = 50)
pred = colnames(pred)[apply(data.frame(pred),1,which.max)]
sum(pred == testResponse)/length(testResponse)
}
library(gbm)
testTrees = testTrees/2
testTrees = testTrees[2:length(testTrees)]
boostClass = foreach(i = 1:4,.combine = 'c') %dopar%{
boost = gbm(as.factor(response)~.,data = data.frame(x),n.trees = 50,shrinkage = .02,interaction.depth = i)
pred = predict(boost,data.frame(testX),n.trees = 50)
pred = colnames(pred)[apply(data.frame(pred),1,which.max)]
sum(pred == testResponse)/length(testResponse)
}
library(randomForest)
library(doParallel)
registerDoParallel(cores = 6)
testTrees = c(1,2,5,10,20,40,60,100,120,180,200)
bagClass = foreach( i = 1:length(testTrees),.combine = 'c') %dopar%
{
bag = randomForest::randomForest(as.factor(response) ~.,data = data.frame(x),mtry =bestComponents,ntree = testTrees[i])
getClassificationRate(bag,testX,testResponse)
}
registerDoParallel(cores = 6)
library(gbm)
testTrees = testTrees/2
testTrees = testTrees[2:length(testTrees)]
boostClass = foreach(i = 1:4,.combine = 'c') %dopar%{
boost = gbm(as.factor(response)~.,data = data.frame(x),n.trees = 50,shrinkage = .02,interaction.depth = i)
pred = predict(boost,data.frame(testX),n.trees = 50)
pred = colnames(pred)[apply(data.frame(pred),1,which.max)]
sum(pred == testResponse)/length(testResponse)
}
library(gbm)
testTrees = testTrees/2
testTrees = testTrees[2:length(testTrees)]
boostClass = foreach(i = 1:4,.combine = 'c') %dopar%{
boost = gbm::gbm(as.factor(response)~.,data = data.frame(x),n.trees = 50,shrinkage = .02,interaction.depth = i)
pred = predict(boost,data.frame(testX),n.trees = 50)
pred = colnames(pred)[apply(data.frame(pred),1,which.max)]
sum(pred == testResponse)/length(testResponse)
}
boostClass
library(gbm)
shrinkageTests = c(.001,.002,.005,.009,.01,.05,.1)
boostClass = foreach(i = 1:length(shrinkageTests),.combine = 'c') %dopar%{
boost = gbm::gbm(as.factor(response)~.,data = data.frame(x),n.trees = 50,shrinkage = .02,interaction.depth = boostClass)
pred = predict(boost,data.frame(testX),n.trees = 50)
pred = colnames(pred)[apply(data.frame(pred),1,which.max)]
sum(pred == testResponse)/length(testResponse)
}
library(gbm)
shrinkageTests = c(.001,.002,.005,.009,.01,.05,.1)
boostClass = foreach(i = 1:length(shrinkageTests),.combine = 'c') %dopar%{
boost = gbm::gbm(as.factor(response)~.,data = data.frame(x),n.trees = 50,shrinkage = shrinkageTests[i],interaction.depth = 3)
pred = predict(boost,data.frame(testX),n.trees = 50)
pred = colnames(pred)[apply(data.frame(pred),1,which.max)]
sum(pred == testResponse)/length(testResponse)
}
shrinkageTests
boostClass
library(gbm)
treeTest = c(100,125,150,200)
boostClass = foreach(i = 1:length(treeTest),.combine = 'c') %dopar%{
boost = gbm::gbm(as.factor(response)~.,data = data.frame(x),n.trees = treeTest[i],shrinkage = .01,interaction.depth = 3)
pred = predict(boost,data.frame(testX),n.trees = 50)
pred = colnames(pred)[apply(data.frame(pred),1,which.max)]
sum(pred == testResponse)/length(testResponse)
}
boostClass
library(gbm)
boost = gbm::gbm(as.factor(response)~.,data = data.frame(x),n.trees = 100,shrinkage = .01,interaction.depth = 3)
pred = predict(boost,data.frame(testX),n.trees = 50)
pred = colnames(pred)[apply(data.frame(pred),1,which.max)]
sum(pred == testResponse)/length(testResponse)
data.frame(pred)
names(data.frame(pred))
data.frame(pred) %>% group_by(pred) %>% summarise(count = n())
library(dplyr)
data.frame(pred) %>% group_by(pred) %>% summarise(count = n())
data.frame(pred) %>% group_by(pred) %>% summarise(count = n()) %>% order_by(count)
data.frame(pred) %>% group_by(pred) %>% summarise(count = n()) %>% order_by()
d
library(dplyr)
data.frame(pred) %>% group_by(pred) %>% summarise(count = n()) %>% order_by(count)
boostedAuthorsCount = data.frame(pred) %>% group_by(pred) %>% summarise(count = n())
boostedAuthorsCount
boostedAuthorsCount %>% order(count)
boostedAuthorsCount %>% arrange(count)
data.frame(pred) %>% group_by(pred) %>% summarise(count = n()) %>% arrange(count,ascending = FALSE)
?arrange
data.frame(pred) %>% group_by(pred) %>% summarise(count = n()) %>% arrange(count)
data.frame(pred) %>% group_by(pred) %>% summarise(count = n()) %>% arrange(count,desc = TRUE)
data.frame(pred) %>% group_by(pred) %>% summarise(count = n()) %>% arrange(count,desc(count))
data.frame(pred) %>% group_by(pred) %>% summarise(count = n()) %>% arrange(count,asc(count))
data.frame(pred) %>% group_by(pred) %>% summarise(count = n()) %>% arrange(count,asec(count))
data.frame(pred) %>% group_by(pred) %>% summarise(count = n()) %>% arrange(count,asce(count))
data.frame(pred) %>% group_by(pred) %>% summarise(count = n()) %>% arrange(desc(count))
library(dplyr)
authorClassification = data.frame(pred) %>% group_by(pred) %>% summarise(count = n()) %>% arrange(desc(count))
authorClassification
authorClassification[1:5,]
authorClassification[(nrow(authorClassification)-5):nrow(authorClassification),]
library(dplyr)
authorClassification = data.frame(pred) %>% group_by(pred) %>% summarise(count = n()) %>% arrange(desc(count))
authorClassification[1:5,]
authorClassification[(nrow(authorClassification)-5):nrow(authorClassification),]
